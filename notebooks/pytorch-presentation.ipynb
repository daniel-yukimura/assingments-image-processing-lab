{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Introduction\n",
    "\n",
    "* PyTorch tensors are essentially like numpy arrays, but they can run on **GPU**.\n",
    "\n",
    "### **Let's take a look on how tensors look like in pytorch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "T = torch.Tensor([[1,2],[3,4]])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n"
     ]
    }
   ],
   "source": [
    "print(T**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You can do inplace operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0848e-31,  3.0906e-41,  0.0000e+00,  0.0000e+00],\n",
      "        [        nan,  0.0000e+00,  1.2271e+01,  1.1319e+21]])\n"
     ]
    }
   ],
   "source": [
    "T = torch.empty(2, 4)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.0500, 0.0500, 0.0500]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.fill_(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2986,  0.0204,  0.9383, -1.2173],\n",
      "        [-0.3505, -1.4784,  0.3386, -0.0081]])\n"
     ]
    }
   ],
   "source": [
    "T += torch.randn(2,4)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3819)\n",
      "-0.38193219900131226\n"
     ]
    }
   ],
   "source": [
    "print(T.mean())\n",
    "print(T.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You can convert numpy to tensor or vise versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.ones(6)\n",
    "print(v)\n",
    "\n",
    "T = torch.from_numpy(v)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tensor and numy array will share their underlying memory locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "T.add_(1)\n",
    "print(T)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From tensor to numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1288, -0.5369, -0.0870],\n",
      "        [ 0.6636,  1.4599,  1.7416],\n",
      "        [ 0.3486,  0.5827,  0.6461]])\n",
      "[[-1.1287965  -0.5369296  -0.08702268]\n",
      " [ 0.6635978   1.459885    1.7415698 ]\n",
      " [ 0.34862456  0.5826633   0.6461347 ]]\n"
     ]
    }
   ],
   "source": [
    "T = torch.randn(3,3)\n",
    "print(T)\n",
    "v = T.numpy()\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation\n",
    "\n",
    "* Any tensor operation done by PyTorch can be automatically differentiated by the **autograd** package.\n",
    "* We only need to write the forward pass, autograd takes care of tracking the computational graph associated, and compute the gradients.\n",
    "* To have its operations tracked by autograd you just need to set the attribute **requires_grad** as **True**.\n",
    "* Every tensor also has a field grad, itself a tensor of same size, type used to accumulate gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThAddBackward object at 0x7fccb0d7f748>\n",
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# A simple example:\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "print(y.grad_fn)\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Modules - Neural Networks\n",
    "\n",
    "* Neural networks can be constructed using the **torch.nn** package.\n",
    "* Our idealized modules are constructed as subclasses of **torch.nn.Module**.\n",
    "* We also use elements of **torch.nn.functional** which are autograd-compliant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7550, -0.9437, -0.9727],\n",
      "        [ 0.9440,  0.4132,  0.1134]])\n",
      "tensor([[1.7550, 0.0000, 0.0000],\n",
      "        [0.9440, 0.4132, 0.1134]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(2,3)\n",
    "print(x)\n",
    "x = F.relu(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([4, 10])\n",
      "bias torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "f = nn.Linear(in_features = 10, out_features = 4)\n",
    "for n, p in f.named_parameters(): print(n, p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(350, 10).normal_()\n",
    "y = f(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a feedforward neural network as a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3366\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2874\n",
      "Epoch [1/5], Step [300/600], Loss: 0.3106\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1440\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1801\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0872\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0701\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1648\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1814\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1003\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1224\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1301\n",
      "Epoch [3/5], Step [100/600], Loss: 0.1409\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0185\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0263\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0580\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1400\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0614\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0103\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0380\n",
      "Epoch [4/5], Step [400/600], Loss: 0.1080\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0327\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0468\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0610\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0176\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0519\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0801\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0516\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0318\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.72 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:image-processing-lab]",
   "language": "python",
   "name": "conda-env-image-processing-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
